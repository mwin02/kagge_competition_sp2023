{"cells":[{"cell_type":"markdown","metadata":{"id":"em3A3hWWXlRT"},"source":["# 2.5 Automatic Differentiation\n","\n","Pytorch constructs computational graph to record the dependencies among different values (tensors). Gradients are automatically calculated through chain rules using the computational graph during backpropagation.\n","\n","Take the example of a single linear layer and squared loss. \n","\n","Let the input be a 2-vector $X=[x_0,x_1]^T$ and the output be a scaler. Weight $w=[w_0,w_1]$, bias $b \\in \\mathbb{R}$, and output $y = w^TX + b$. Let ground-truth target $z \\in \\mathbb{R}$ and the squared loss $l = (y-z)^2$.\n","\n","Using chain rule, we can manually and tediously calculate the partial derivative with respect to any variable.\n","\n","For example, \n","$$ \n","\\begin{align}\n","&\\frac{\\partial l}{\\partial w_0} \\\\\n","&= \\frac{\\partial l}{\\partial{y}} \\frac{\\partial{y}}{\\partial (w^TX)} \\frac{\\partial (w^TX)}{\\partial (w_0 * x_0)} \\frac{\\partial (w_0 * x_0)}{\\partial (w_0)} \\\\ \n","&= 2(y-z)* 1 * 1 * x_0 \\\\\n","&= 2(y-z)x_0\n","\\end{align} \n","$$\n","\n","If we pick input $X = [1,2]^T$, $w = [0.5,0.5]$, $b = 0.1$ and $z = 1$, we will have $y = 1 * 0.5 + 2 * 0.5 + 0.1 = 1.6$ and $l = (1.6-1)^2 = 0.36$. \n","\n","Then $\\frac{\\partial l}{\\partial w_0} = 2 *(1.6-1) * 1 = 1.2$\n","\n","Similarly, $\\frac{\\partial l}{\\partial w_1} = 2 *(1.6-1) * 2 = 2.4$, and the full gradient $\\nabla_w l = \\begin{bmatrix}1.2 \\\\ 2.4\\end{bmatrix}$\n","\n","We can calculate the same result easily using pytorch automatic differentiation by calling the `backward()` function of a target tensor. It will also calculate the gradient for all the tensors involved in computing the value of the target tensor (unless gradient of a tensor is explicitly marked as unneeded): "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TNve0xZJXlRb","executionInfo":{"status":"ok","timestamp":1680898823443,"user_tz":420,"elapsed":9375,"user":{"displayName":"Evan Yao","userId":"02394524845347225364"}},"outputId":"8ffe37e1-36c6-41db-dd06-ebddba36234c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Gradient of w:\ttensor([[1.2000, 2.4000]])\n","Gradient of x:\ttensor([0.6000, 0.6000])\n","Gradient of b:\t1.2000000476837158\n","Gradient of z:\tNone\n"]}],"source":["import torch \n","\n","# use the requires_grad attribute to control whether the calculate the gradient for the tensor\n","x = torch.tensor([[1.],[2.]], requires_grad=True)\n","# The same as setting requires_grad_ later to True:\n","# x = torch.tensor([[1.],[2.]])\n","# x.requires_grad_(True)\n","w = torch.tensor([[0.5,0.5]], requires_grad=True)\n","b = torch.tensor(0.1, requires_grad=True)\n","y = w @ x + b \n","# Gradients are disabled by default for tensors created using the torhc.tensor constructor\n","z = torch.tensor(1.0)\n","loss = (y-z) ** 2\n","# Use backpropagation to compute gradients\n","loss.backward()\n","\n","print(f\"Gradient of w:\\t{w.grad}\")\n","# flattened gradient of x only for display \n","print(f\"Gradient of x:\\t{x.grad.flatten()}\")\n","print(f\"Gradient of b:\\t{b.grad}\")\n","# gradient disabled, so is None \n","print(f\"Gradient of z:\\t{z.grad}\")\n"]},{"cell_type":"markdown","metadata":{"id":"4nSGzXWfXlRe"},"source":["We can see that the partial derivative of $w_0$ is correctly calculated. In fact, the gradient of vector $w$, $x$, and $b$ are all calculated. Note that the gradient of the $z$ is None, as its requires_grad parameter is not set to True. "]},{"cell_type":"markdown","metadata":{"id":"Lqy5PxNuXlRf"},"source":["Gradients are attributes of tensors and will accumulate as computation happens. New gradietn value will be added to the old gradient value: "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ggz6mB1lXlRh","outputId":"4d3d3b18-d43b-4cc6-8a99-a1a5435cd151"},"outputs":[{"name":"stdout","output_type":"stream","text":["w gradient after previous calculation \ttensor([[1.2000, 2.4000]])\n","\n","Result value: \t1.0\n","Accumulated w gradient: \ttensor([[2.2000, 3.4000]]) \n","\n","Result value iter2: \t1.0\n","Accumulated w gradient iter2: \ttensor([[3.2000, 4.4000]])\n"]}],"source":["print(f\"w gradient after previous calculation \\t{w.grad}\\n\")\n","# some calculation\n","result = w.sum()\n","result.backward()\n","print(f\"Result value: \\t{result}\")\n","print(f\"Accumulated w gradient: \\t{w.grad} \\n\")\n","\n","# conduct the same calculation again. result2 is not changed, but gradient of 2 is changed \n","result = w.sum()\n","result.backward()\n","print(f\"Result value iter2: \\t{result}\")\n","print(f\"Accumulated w gradient iter2: \\t{w.grad}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dJx3YIvrXlRi"},"source":["The gradient can be manually set to 0 with `tensor.zero_()` (or any other values, for example `one_(), fill_()`, etc. Refer to pytorch documentations for other options): "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xjHi9YMKXlRj","outputId":"bf587f1f-f4d7-4eb9-b907-68449f7cd091"},"outputs":[{"name":"stdout","output_type":"stream","text":["Result value: \t1.0\n","Accumulated w gradient: \ttensor([[1., 1.]]) \n","\n","Result value iter2: \t1.0\n","Accumulated w gradient iter2: \ttensor([[1., 1.]]) \n","\n"]}],"source":["w.grad.zero_()\n","\n","result = w.sum()\n","result.backward()\n","print(f\"Result value: \\t{result}\")\n","print(f\"Accumulated w gradient: \\t{w.grad} \\n\")\n","\n","# If we reset the gradient, both results should agree\n","w.grad.zero_()\n","result = w.sum()\n","result.backward()\n","print(f\"Result value iter2: \\t{result}\")\n","print(f\"Accumulated w gradient iter2: \\t{w.grad} \\n\")\n"]},{"cell_type":"markdown","metadata":{"id":"jc-Mcq5sXlRl"},"source":["## 2.5.2 Backward for Non-scalar variables\n","\n","If instead of a scalar, our calculation outputs a vector, directly calling `backward()` on the output vector will produce an error, as there will be multiple gradients to choose from. For example, we calculate \n","\n","$$y = w_0 * X + w_1 * X$$ \n","\n","(w_0 and w_1 are scalars, X is a 2-vector), then instead of $\\nabla_w y$, we will have a Jacobian matrix \n","\n","$$\n","J = \\begin{bmatrix}\n","    \\frac{\\partial y_0}{\\partial w_0} & \\frac{\\partial y_0}{\\partial w_1} \\\\\n","    \\frac{\\partial y_1}{\\partial w_0} & \\frac{\\partial y_1}{\\partial w_1}\n","\\end{bmatrix}\n","$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vEKMewhJXlRm","outputId":"7d87268e-0e0a-40d2-e4fc-f22a66f42e32"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of y_r: torch.Size([2, 1])\n"]}],"source":["x = torch.tensor([[1.],[2.]], requires_grad=True)\n","w = torch.tensor([0.5,0.5], requires_grad=True)\n","y_r = w[0] * x + w[1] * x\n","print(f\"Shape of y_r: {y_r.shape}\")\n","# Directly calling backward on y will result an error\n","# y_r.backward()"]},{"cell_type":"markdown","metadata":{"id":"ln7lL-UkXlRm"},"source":["The `gradient` parameter of `backward()` function can be used to calculate a matrix vector multiplication between the Jacobian matrix and a vector. For example, denote the gradient vector as $v = [v_0,v_1]^T$, then `y_r.backward(gradient=v)` will calculate \n","$$\n","v^T J = \\begin{bmatrix}\n","    v_0 * \\frac{\\partial y_0}{\\partial w_0} + v_1 * \\frac{\\partial y_1}{\\partial w_0}  \\\\\n","    v_0 * \\frac{\\partial y_0}{\\partial w_1} + v_1 * \\frac{\\partial y_1}{\\partial w_1}\n","\\end{bmatrix}\n","$$\n","\n","Setting `gradient` to a 1 vector ([1,1] in the above example) will produce the sum of all gradient with respect to the target tensor. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4vB0VOShXlRn","outputId":"d7d4015f-8936-4882-9460-77bcc65ea6ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sum of gradient: tensor([3., 3.])\n"]}],"source":["# set gradient to be a 1 vector that matches the shape of y \n","y_r.backward(gradient=torch.ones((2,1)))\n","print(f\"Sum of gradient: {w.grad}\")\n","sumed_grad = w.grad "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x0ucv4L1XlRo","outputId":"618693be-a104-48e6-f256-97f00c1e8d78"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1., 1.])\n","tensor([2., 2.])\n"]},{"data":{"text/plain":["tensor([True, True])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.tensor([[1.],[2.]], requires_grad=True)\n","w = torch.tensor([0.5,0.5], requires_grad=True)\n","y_r = w[0] * x + w[1] * x\n","y_r[0].backward()\n","p_y0_p_w = w.grad.clone()\n","print(p_y0_p_w)\n","\n","# Clear gradient. \n","x.grad.zero_()\n","w.grad.zero_()\n","y_r = w[0] * x + w[1] * x\n","y_r[1].backward()\n","p_y1_p_w = w.grad.clone()\n","print(p_y1_p_w)\n","\n","# gradient results are the same \n","p_y1_p_w + p_y0_p_w == sumed_grad"]},{"cell_type":"markdown","metadata":{"id":"w2ePdY6nXlRo"},"source":["## 2.5.3 Detaching Computation \n","\n","If we do not want to calculate the gradient of some tensor, We can detach any tensor (from the computational graph) using `detach()` function so that the gradients of tensors used to compute the detached tensor are not calculated. Using example from the book, for $y = x * x$, and $z = y * x$, if $y$ is not detached, $\\nabla_x z = \\nabla_x x^3 = 3x^2$ (a little abuse of notation for element-wise power). After detaching $y$, computation of $y$ no longer affect gradient calculation of $x$, and then the gradient will just be value of $y$. We can validate this to be true: "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1gffGBW1XlRp","outputId":"a529dea0-8f2e-4a58-de9c-e69bd63edd9f"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[True],\n","        [True]])\n"]}],"source":["x.grad.zero_()\n","y = x * x\n","u = y.detach()\n","z = u * x\n","# computation x * x is not included in computing the gradient\n","z.sum().backward()\n","print(x.grad == u)"]},{"cell_type":"markdown","metadata":{"id":"yaM69qZAXlRp"},"source":["Even though $y$ is detached from the computational graph of calculating $z$, we can still backpropagate from within the calculation of $y$ to get gradient. For example, $\\nabla_x sum(y) = 2 * x$. As shown in the example from the book: "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cMSny5PmXlRp","outputId":"60142578-154b-4125-d3a2-8308ade2f902"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[True],\n","        [True]])\n"]}],"source":["x.grad.zero_()\n","# calculation of y can still be backpropagated explicitly \n","y.sum().backward()\n","print(x.grad == 2 * x)"]},{"cell_type":"markdown","metadata":{"id":"mtlz8TGyXlRq"},"source":["## 2.5.4 Gradients and Python Control Flow\n","\n","In addition to simple arithmatic operations, gradients can also be calculated and accumulated when other python control flows, such as loops or conditional statements, are used. The book provides a simple example: "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pe28Rh2QXlRq","outputId":"e6a745d4-a0c3-40ed-91c2-3db7c1d724e8"},"outputs":[{"data":{"text/plain":["tensor(True)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["def f(a):\n","    b = a * 2\n","    while b.norm() < 1000:\n","        b = b * 2\n","    if b.sum() > 0:\n","        c = b\n","    else:\n","        c = 100 * b\n","    return c\n","\n","# create a random \n","a = torch.randn(size=(), requires_grad=True)\n","d = f(a)\n","d.backward()\n","a.grad == d / a\n"]},{"cell_type":"markdown","metadata":{"id":"GFME-OT3XlRr"},"source":["## 2.7 Documentations\n","\n","`dir()` give the full list of functions and attributes of a module/object. \n","\n","`help()` displays the help messages for function or class. In jupyer notebook, \"?\" can also be used to achieve the same result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uDS7Gwx1XlRr","outputId":"ff99887d-720c-4896-dc98-d4f3157ae9ac"},"outputs":[{"data":{"text/plain":["['LinAlgError',\n"," 'Tensor',\n"," '__builtins__',\n"," '__cached__',\n"," '__doc__',\n"," '__file__',\n"," '__loader__',\n"," '__name__',\n"," '__package__',\n"," '__path__',\n"," '__spec__',\n"," '_add_docstr',\n"," '_linalg',\n"," 'cholesky',\n"," 'cholesky_ex',\n"," 'common_notes',\n"," 'cond',\n"," 'cross',\n"," 'det',\n"," 'diagonal',\n"," 'eig',\n"," 'eigh',\n"," 'eigvals',\n"," 'eigvalsh',\n"," 'householder_product',\n"," 'inv',\n"," 'inv_ex',\n"," 'ldl_factor',\n"," 'ldl_factor_ex',\n"," 'ldl_solve',\n"," 'lstsq',\n"," 'lu',\n"," 'lu_factor',\n"," 'lu_factor_ex',\n"," 'lu_solve',\n"," 'matmul',\n"," 'matrix_exp',\n"," 'matrix_norm',\n"," 'matrix_power',\n"," 'matrix_rank',\n"," 'multi_dot',\n"," 'norm',\n"," 'pinv',\n"," 'qr',\n"," 'slogdet',\n"," 'solve',\n"," 'solve_ex',\n"," 'solve_triangular',\n"," 'svd',\n"," 'svdvals',\n"," 'sys',\n"," 'tensorinv',\n"," 'tensorsolve',\n"," 'torch',\n"," 'vander',\n"," 'vecdot',\n"," 'vector_norm']"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["import torch \n","dir(torch.linalg)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tvLEnqfxXlRs","outputId":"bf5749a5-e6f4-4d89-8ae0-9d450da64aaf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Help on built-in function ldexp in module torch:\n","\n","ldexp(...)\n","    ldexp(input, other, *, out=None) -> Tensor\n","    \n","    Multiplies :attr:`input` by 2**:attr:`other`.\n","    \n","    .. math::\n","        \\text{{out}}_i = \\text{{input}}_i * 2^\\text{{other}}_i\n","    \n","    \n","    Typically this function is used to construct floating point numbers by multiplying\n","    mantissas in :attr:`input` with integral powers of two created from the exponents\n","    in :attr:`other`.\n","    \n","    Args:\n","        input (Tensor): the input tensor.\n","        other (Tensor): a tensor of exponents, typically integers.\n","    \n","    Keyword args:\n","        out (Tensor, optional): the output tensor.\n","    \n","    Example::\n","    \n","        >>> torch.ldexp(torch.tensor([1.]), torch.tensor([1]))\n","        tensor([2.])\n","        >>> torch.ldexp(torch.tensor([1.0]), torch.tensor([1, 2, 3, 4]))\n","        tensor([ 2.,  4.,  8., 16.])\n","\n"]}],"source":["import torch \n","help(torch.ldexp) \n","# same as the following in jupyernotebook\n","# np.busday_count?"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}